# Guia R√°pido: Criar Agente On-Premise

Guia pr√°tico com exemplos de JSON para criar agentes usando modelos on-premise.

## üöÄ Passo a Passo

### 1Ô∏è‚É£ Configure o `.env`

```env
# API On-Premise
ONPREMISE_API_BASE_URL=https://apidesenv.go.gov.br/ia/modelos-linguagem-natural/v2.0/
ONPREMISE_CHAT_ENDPOINT=/chat

# OAuth
ONPREMISE_TOKEN_URL=https://apidesenv.go.gov.br/token
ONPREMISE_CONSUMER_KEY=X1mgu5MTHdp6VxZEemXCLZ2FGloa
ONPREMISE_CONSUMER_SECRET=d1z8Pg2ZmHrZz9aFsuUlAFKRn7Aa
ONPREMISE_OAUTH_GRANT_TYPE=client_credentials

# SSL (desabilitar para desenvolvimento)
VERIFY_SSL=false
```

### 2Ô∏è‚É£ Fa√ßa Login na Aplica√ß√£o

Use o endpoint `POST /api/login` para obter um token JWT.

### 3Ô∏è‚É£ Crie o Agente

Use o endpoint `POST /api/agents` com o JSON do agente.

## üìù Exemplo Principal: Agente Completo (CORRIGIDO)

**JSON que voc√™ forneceu originalmente, agora corrigido:**

```json
{
  "name": "Assistente Completo",
  "description": "Agente vers√°til que pode realizar c√°lculos e informar a hora",
  "instruction": "Voc√™ √© um assistente √∫til e vers√°til. Voc√™ pode:\n1. Realizar c√°lculos matem√°ticos usando a ferramenta 'calculator'\n2. Informar a hora atual em qualquer timezone usando a ferramenta 'get_current_time'\n\nSeja amig√°vel, prestativo e use portugu√™s brasileiro. Sempre explique o que est√° fazendo.",
  "model": "qwen3:30b-a3b-instruct-2507-q4_K_M",
  "tools": ["calculator", "get_current_time"]
}
```

**‚ö†Ô∏è MUDAN√áAS IMPORTANTES:**

1. ‚úÖ **Modelo alterado** de `"gemini-2.0-flash"` para `"qwen3:30b-a3b-instruct-2507-q4_K_M"`
   - `gemini-2.0-flash` ‚Üí vai para Google Gemini API (n√£o on-premise)
   - `qwen3:30b-a3b-instruct-2507-q4_K_M` ‚Üí usa API on-premise ‚úÖ

2. ‚úÖ **Ferramentas est√£o corretas:**
   - `calculator` ‚úÖ
   - `get_current_time` ‚úÖ

### üí° **Uso Opcional de Prefixo Expl√≠cito**

Voc√™ tamb√©m pode usar o prefixo `onpremise-` ou `local-` para for√ßar explicitamente o uso do provider on-premise:

```json
{
  "model": "onpremise-qwen3:30b-a3b-instruct-2507-q4_K_M"
}
```

**Quando usar o prefixo?**
- ‚úÖ Para deixar expl√≠cito que √© on-premise
- ‚úÖ Em ambientes com m√∫ltiplos providers configurados
- ‚úÖ Para debugging e testes
- ‚úÖ Quando quiser garantir 100% que vai usar on-premise

**Prefixos suportados:**
- `onpremise-` ‚Üí `onpremise-qwen3:30b`
- `local-` ‚Üí `local-qwen3:30b`

**Ambos funcionam da mesma forma!**

## üéØ Outros Exemplos de Modelos On-Premise

### Op√ß√£o 1: Modelo R√°pido e Leve

```json
{
  "name": "Assistente R√°pido",
  "description": "Respostas r√°pidas para tarefas simples",
  "model": "llama3.2:3b",
  "instruction": "Voc√™ √© um assistente r√°pido e direto.",
  "tools": []
}
```

### Op√ß√£o 2: Especialista em Programa√ß√£o

```json
{
  "name": "Assistente de C√≥digo",
  "description": "Especialista em programa√ß√£o",
  "model": "qwen3-coder:30b",
  "instruction": "Voc√™ √© um expert em programa√ß√£o. Ajude com c√≥digo e debugging.",
  "tools": []
}
```

### Op√ß√£o 3: Racioc√≠nio Avan√ßado

```json
{
  "name": "Assistente de Racioc√≠nio",
  "description": "Especialista em problemas complexos",
  "model": "deepseek-r1:14b",
  "instruction": "Voc√™ √© especialista em resolver problemas complexos.",
  "tools": ["calculator"]
}
```

### Op√ß√£o 4: Alta Qualidade

```json
{
  "name": "Assistente Premium",
  "description": "M√°xima qualidade nas respostas",
  "model": "gemma3:27b-it-q4_K_M",
  "instruction": "Voc√™ √© um assistente de elite. Forne√ßa respostas detalhadas.",
  "tools": ["calculator", "get_current_time"]
}
```

### Op√ß√£o 5: GPT Open Source

```json
{
  "name": "Assistente GPT-OSS",
  "description": "Usando GPT Open Source",
  "model": "gpt-oss:20b",
  "instruction": "Voc√™ √© um assistente √∫til em portugu√™s brasileiro.",
  "tools": []
}
```

## ‚úÖ Checklist Completo

### Configura√ß√£o

- [ ] ‚úÖ Arquivo `.env` configurado
- [ ] ‚úÖ `ONPREMISE_API_BASE_URL` definida
- [ ] ‚úÖ `ONPREMISE_CHAT_ENDPOINT=/chat` definido
- [ ] ‚úÖ Credenciais OAuth configuradas
- [ ] ‚úÖ `VERIFY_SSL=false` (se necess√°rio)
- [ ] ‚úÖ Servidor rodando (`python -m uvicorn src.api.main:app --reload --port 8001`)

### Autentica√ß√£o

- [ ] ‚úÖ Usu√°rio criado no sistema
- [ ] ‚úÖ Login realizado com sucesso
- [ ] ‚úÖ Token JWT obtido e salvo

### Modelo

- [ ] ‚úÖ Modelo escolhido da lista dispon√≠vel
- [ ] ‚úÖ Modelo usa formato com `:` (ex: `qwen3:30b`)
- [ ] ‚ùå **N√ÉO** usar `gemini-*` (vai para Google)
- [ ] ‚ùå **N√ÉO** usar `gpt-4o`, `gpt-3.5-turbo` (vai para OpenAI)

### Ferramentas

- [ ] ‚úÖ `calculator` - para c√°lculos matem√°ticos
- [ ] ‚úÖ `get_current_time` - para informa√ß√µes de tempo
- [ ] ‚ùå **N√ÉO** usar `"time"` (nome incorreto)

### Cria√ß√£o

- [ ] ‚úÖ Endpoint correto (`POST /api/agents`)
- [ ] ‚úÖ Header `Authorization` com Bearer token
- [ ] ‚úÖ JSON v√°lido no body
- [ ] ‚úÖ Resposta HTTP 201 Created

## üêõ Troubleshooting

### Problema: "gemini-2.0-flash n√£o usa on-premise"

**Solu√ß√£o:** Modelos Gemini (com h√≠fen `-`) usam Google API. Use modelos com `:` para on-premise.

```diff
- "model": "gemini-2.0-flash"  ‚ùå
+ "model": "qwen3:30b-a3b-instruct-2507-q4_K_M"  ‚úÖ
```

### Problema: "Tool 'time' not found"

**Solu√ß√£o:** O nome correto da ferramenta √© `get_current_time`.

```diff
- "tools": ["calculator", "time"]  ‚ùå
+ "tools": ["calculator", "get_current_time"]  ‚úÖ
```

### Problema: "Modelo n√£o encontrado"

**Solu√ß√£o:** Verifique a lista de modelos dispon√≠veis usando o endpoint `GET /models` da API on-premise.

### Problema: "Erro 404 no chat endpoint"

**Solu√ß√£o:** Verifique se `ONPREMISE_CHAT_ENDPOINT=/chat` est√° no `.env`.

### Problema: "SSL Certificate Error"

**Solu√ß√£o:** Adicione no `.env`:

```env
VERIFY_SSL=false
```

‚ö†Ô∏è **ATEN√á√ÉO:** Use `VERIFY_SSL=false` apenas em desenvolvimento!

## üìä Tabela de Modelos por Uso

| Caso de Uso | Modelo Recomendado | Tamanho | Velocidade |
|-------------|-------------------|---------|-----------|
| **Uso Geral** | `qwen3:30b-a3b-instruct-2507-q4_K_M` | 30B | ‚≠ê‚≠ê‚≠ê |
| **Programa√ß√£o** | `qwen3-coder:30b` | 30B | ‚≠ê‚≠ê‚≠ê |
| **R√°pido** | `llama3.2:3b` | 3B | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Racioc√≠nio** | `deepseek-r1:14b` | 14B | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Alta Qualidade** | `gemma3:27b-it-q4_K_M` | 27B | ‚≠ê‚≠ê‚≠ê |
| **Equil√≠brio** | `gemma3:12b-it-fp16` | 12B | ‚≠ê‚≠ê‚≠ê‚≠ê |

## üöÄ Como Usar os JSONs

1. **Via API REST:** Use o endpoint `POST /api/agents` com o JSON no body
2. **Via Interface Web:** Cole o JSON na interface de cria√ß√£o de agentes
3. **Via Swagger:** Acesse `http://localhost:8001/docs` e use o endpoint `/api/agents`

## üìö Pr√≥ximos Passos

1. ‚úÖ Criar mais agentes com diferentes modelos
2. ‚úÖ Testar diferentes ferramentas
3. ‚úÖ Ajustar par√¢metros (temperature, num_predict, etc.)
4. ‚úÖ Integrar com interface web
5. ‚úÖ Monitorar performance dos modelos

## üéì Dicas Importantes

1. **Sempre use modelos com `:` para on-premise**
   - ‚úÖ `qwen3:30b`, `llama3.1:8b`, `gpt-oss:20b`
   - ‚ùå `gemini-2.0-flash`, `gpt-4o`

2. **Nomes corretos das ferramentas**
   - ‚úÖ `calculator`, `get_current_time`
   - ‚ùå `time`, `calculator_tool`

3. **Configure OAuth corretamente**
   - Token expira ap√≥s 1 hora
   - Sistema renova automaticamente

4. **Escolha o modelo adequado**
   - R√°pido: `llama3.2:3b`
   - Balanceado: `qwen3:30b-a3b-instruct-2507-q4_K_M`
   - Qualidade: `gemma3:27b-it-q4_K_M`

---

**Pronto para come√ßar! üöÄ**

