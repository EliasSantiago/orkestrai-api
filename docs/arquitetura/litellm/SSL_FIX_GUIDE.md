# üîß Guia R√°pido: Corrigir Erro SSL Certificate Verification

Este guia mostra **passo a passo** como corrigir o erro SSL que voc√™ est√° enfrentando.

---

## üî¥ Erro que voc√™ est√° vendo:

```
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] 
certificate verify failed: self-signed certificate in certificate chain
```

---

## ‚úÖ Solu√ß√£o (3 minutos)

### Passo 1: Edite seu arquivo `.env`

Abra o arquivo `.env` na raiz do projeto e adicione ou modifique a seguinte linha:

```bash
# SSL/TLS Configuration
# WARNING: Only disable SSL verification in development environments!
VERIFY_SSL=false
```

**üí° Dica**: Se a linha `VERIFY_SSL` j√° existir, apenas mude para `false`.

### Passo 2: Reinicie o servidor

Pare o servidor atual (`Ctrl+C`) e reinicie:

```bash
./scripts/start_backend.sh
```

### Passo 3: Verifique os logs

Voc√™ deve ver esta mensagem no startup:

```
‚ö†Ô∏è  SSL verification is DISABLED. This is insecure and should only be used in development!
‚úì LiteLLM provider initialized (unified LLM gateway)
```

### Passo 4: Teste o chat novamente

```bash
curl -X 'POST' \
  'http://localhost:8001/api/agents/chat' \
  -H 'accept: application/json' \
  -H 'Authorization: Bearer YOUR_TOKEN' \
  -H 'Content-Type: application/json' \
  -d '{
    "agent_id": 8,
    "message": "Ol√°!",
    "session_id": ""
  }'
```

---

## üîí Por que isso acontece?

Voc√™ est√° em um **ambiente corporativo** que usa:
- **Proxy SSL/TLS** para interceptar tr√°fego HTTPS
- **Certificados auto-assinados** (self-signed certificates)
- **Inspe√ß√£o SSL** para seguran√ßa corporativa

O Python/LiteLLM n√£o confia nesses certificados por padr√£o, causando o erro.

---

## ‚ö†Ô∏è Importante: Seguran√ßa

### Para Desenvolvimento/Staging: ‚úÖ OK usar `VERIFY_SSL=false`

Esta √© a solu√ß√£o mais r√°pida e funciona bem para desenvolvimento.

### Para Produ√ß√£o: ‚ùå N√ÉO use `VERIFY_SSL=false`

Em produ√ß√£o, voc√™ **DEVE** usar uma das seguintes alternativas:

#### Op√ß√£o 1: Instalar Certificado CA Corporativo

```bash
# Ubuntu/Debian
sudo cp certificado-ca-empresa.crt /usr/local/share/ca-certificates/
sudo update-ca-certificates

# Depois reinicie a API
./scripts/start_backend.sh
```

#### Op√ß√£o 2: Configurar CA Bundle

No seu `.env`:

```bash
VERIFY_SSL=true
REQUESTS_CA_BUNDLE=/caminho/para/ca-bundle.crt
SSL_CERT_FILE=/caminho/para/ca-bundle.crt
```

#### Op√ß√£o 3: Configurar Proxy Corretamente

No seu `.env`:

```bash
VERIFY_SSL=true
HTTP_PROXY=http://proxy.empresa.com:8080
HTTPS_PROXY=http://proxy.empresa.com:8080
NO_PROXY=localhost,127.0.0.1
```

---

## üìã Configura√ß√£o Completa do .env

Seu arquivo `.env` deve ter **no m√≠nimo**:

```bash
# ==============================================
# LiteLLM Configuration (OBRIGAT√ìRIO)
# ==============================================

LITELLM_ENABLED=true
LITELLM_VERBOSE=false
LITELLM_NUM_RETRIES=3
LITELLM_REQUEST_TIMEOUT=600

# ==============================================
# SSL/TLS (Para corrigir erro SSL)
# ==============================================

VERIFY_SSL=false  # ‚ö†Ô∏è  Apenas em desenvolvimento!

# ==============================================
# LLM Provider API Keys (pelo menos 1)
# ==============================================

# Google Gemini (https://aistudio.google.com/apikey)
GOOGLE_API_KEY=AIzaSy...

# OpenAI (https://platform.openai.com/api-keys)
OPENAI_API_KEY=sk-...

# Ollama (local)
OLLAMA_API_BASE_URL=http://localhost:11434

# ==============================================
# Web Search (Opcional mas recomendado)
# ==============================================

# Tavily API (https://tavily.com/)
TAVILY_API_KEY=tvly-...

# ==============================================
# Database & Redis
# ==============================================

DATABASE_URL=postgresql://agentuser:agentpass@localhost:5432/agentsdb
REDIS_HOST=localhost
REDIS_PORT=6379

# ==============================================
# JWT
# ==============================================

SECRET_KEY=sua-chave-secreta-aqui
```

---

## üß™ Como testar se funcionou

### Teste 1: Verificar startup

Ap√≥s reiniciar, deve aparecer:

```
‚úì LiteLLM provider initialized (unified LLM gateway)
  ‚Üí All models will be routed through LiteLLM
  ‚Üí Supported: Gemini, OpenAI, Claude, Ollama, Azure, and 100+ more
```

### Teste 2: Fazer requisi√ß√£o de chat

```bash
curl -X 'POST' \
  'http://localhost:8001/api/agents/chat' \
  -H 'Authorization: Bearer YOUR_TOKEN' \
  -H 'Content-Type: application/json' \
  -d '{
    "agent_id": 8,
    "message": "Teste de conex√£o",
    "session_id": ""
  }'
```

**Sucesso**: Voc√™ deve receber uma resposta do LLM (n√£o um erro 500).

---

## üêõ Outros problemas comuns

### Problema: "Requested tools not found: ['web_search']"

**Solu√ß√£o**: Configure a API do Tavily:

```bash
# No .env
TAVILY_API_KEY=tvly-xxxxxxxxxxxxxxxxx
```

Depois crie um agente com a ferramenta correta:

```bash
curl -X POST http://localhost:8001/api/agents \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d @examples/agents/tavily_web_researcher.json
```

### Problema: "Invalid Model Error"

**Solu√ß√£o**: Use o formato `provider/model-name`:

‚ùå Errado: `"model": "gpt-4o-mini"`  
‚úÖ Correto: `"model": "openai/gpt-4o-mini"`

‚ùå Errado: `"model": "gemini-2.5-flash"`  
‚úÖ Correto: `"model": "gemini/gemini-2.5-flash"`

---

## üìö Pr√≥ximos passos

1. ‚úÖ **Corre√ß√£o SSL aplicada** (voc√™ est√° aqui)
2. üìñ Leia: [TROUBLESHOOTING.md](./TROUBLESHOOTING.md) - Outros problemas comuns
3. üéØ Teste: [USAGE_EXAMPLES.md](../../../examples/agents/USAGE_EXAMPLES.md) - Exemplos pr√°ticos
4. üîß Configure: [SETUP.md](./SETUP.md) - Setup completo

---

## üí¨ Precisa de ajuda?

- **Documenta√ß√£o completa**: `docs/arquitetura/litellm/`
- **Exemplos de agentes**: `examples/agents/`
- **LiteLLM oficial**: https://docs.litellm.ai/docs/

---

**√öltima atualiza√ß√£o**: 2025-11-12

